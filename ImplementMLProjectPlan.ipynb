{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will implement the machine learning project plan you created in the written assignment. You will:\n",
    "\n",
    "1. Load your data set and save it to a Pandas DataFrame.\n",
    "2. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "3. Prepare your data for your model and create features and a label.\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "You have chosen to work with one of four data sets. The data sets are located in a folder named \"data.\" The file names of the three data sets are as follows:\n",
    "\n",
    "* The \"adult\" data set that contains Census information from 1994 is located in file `adultData.csv`\n",
    "* The airbnb NYC \"listings\" data set is located in file  `airbnbListingsData.csv`\n",
    "* The World Happiness Report (WHR) data set is located in file `WHR2018Chapter2OnlineData.csv`\n",
    "* The book review data set is located in file `bookReviewsData.csv`\n",
    "\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load your data using `pd.read_csv()` and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"adultData.csv\")\n",
    "df = pd.read_csv(adultDataSet_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "The next step is to inspect and analyze your data set with your machine learning problem and project plan in mind. \n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. \n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# First drop the columns that would create a bias in the model (race, sex_selfID, and native-country), and drop the income binary because it is the label\n",
    "features_list = df.drop(columns = ['race', 'sex_selfID','native-country', 'income_binary', 'fnlwgt', 'education-num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                73\n",
       "workclass           8\n",
       "education          16\n",
       "marital-status      7\n",
       "occupation         14\n",
       "relationship        6\n",
       "capital-gain      106\n",
       "capital-loss       92\n",
       "hours-per-week     94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the number of unique values for each column\n",
    "features_list.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                True\n",
       "workclass          True\n",
       "education         False\n",
       "marital-status    False\n",
       "occupation         True\n",
       "relationship      False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find any null values\n",
    "features_list.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the missing values in the age column, with the mean\n",
    "mean_ages = features_list['age'].mean()\n",
    "features_list['age'].fillna(value = mean_ages, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace all the missing values in hours per week, with the mean\n",
    "mean_hours_per_week = features_list['hours-per-week'].mean()\n",
    "features_list['hours-per-week'].fillna(value = mean_hours_per_week, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categorical values with the top 10 items from each column\n",
    "top_10_workclass = features_list['workclass'].value_counts().head(10).index\n",
    "for value in top_10_workclass: \n",
    "    features_list['workclass'+ value ] = np.where(features_list['workclass']== value, 1,0)\n",
    "features_list.drop(columns = 'workclass', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_education = features_list['education'].value_counts().head(10).index\n",
    "for value in top_10_education:\n",
    "    features_list['education'+ value] = np.where(features_list['education']== value, 1,0)\n",
    "features_list.drop(columns = 'education', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_maritalstatus = features_list['marital-status'].value_counts().head(10).index\n",
    "for value in top_10_maritalstatus:\n",
    "    features_list['marital-status' + value] = np.where(features_list['marital-status'] == value, 1, 0)\n",
    "features_list.drop(columns = 'marital-status', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_occupation = features_list['occupation'].value_counts().head(10).index\n",
    "for value in top_10_occupation:\n",
    "    features_list['occupation' + value] = np.where(features_list ['occupation']== value, 1, 0)\n",
    "features_list.drop(columns = 'occupation', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_relationship = features_list['relationship'].value_counts().head(10).index\n",
    "for value in top_10_relationship:\n",
    "    features_list['relationship'+ value] = np.where(features_list['relationship']== value, 1, 0)\n",
    "features_list.drop(columns = 'relationship', inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. You will:\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#Now take the encoded data and apply a logistic regression model to predict the income binary\n",
    "#assign the label to y, which is income binary \n",
    "#assign the features to X, which is the features_list\n",
    "y = df['income_binary']\n",
    "X = features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression model to the data\n",
    "def train_test_LR(X_train, y_train, X_test, y_test, c = 1):\n",
    "    model = LogisticRegression(C = c, max_iter = 1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    probability_predictions = model.predict_proba(X_test)\n",
    "    l_loss = log_loss(y_test, probability_predictions)\n",
    "    class_label_predictions = model.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "    \n",
    "    return l_loss, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.3376896296375336\n",
      "Accuracy: 0.8433901427913404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#analyze the results of the logistic regression model\n",
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the C hyperparameter to yield a better accuracy\n",
    "cs = [10** i for i in range(-10,10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#find the log loss and accuracy score for every model\n",
    "ll_cs = []\n",
    "acc_cs = []\n",
    "for c in cs:\n",
    "    l_loss, acc_score = train_test_LR(X_train, y_train, X_test, y_test, c)\n",
    "    ll_cs.append(l_loss)\n",
    "    acc_cs.append(acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
