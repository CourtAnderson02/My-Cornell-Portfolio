# -*- coding: utf-8 -*-
"""BTT Data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rfOtD7NoqHlfAHuS3-n8r7vkqthCN8sc
"""

! pip install kaggle

"""**Instruction:**
download your kaggle API with go to your Kaggle account settings and click on
`Create New API Token`. This will download a file called `kaggle.json `
to your computer. Then upload to google colab file
"""

!mkdir /.kaggle
!mv kaggle.json /.kaggle
!mv /.kaggle /root/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c bttai-nybg-2024

!unzip bttai-nybg-2024.zip

"""**Train Images Retrieval and Assignment into Subfolders**"""

import os
import shutil
import pandas as pd

# Define paths
folder_path = "/content/BTTAIxNYBG-train/BTTAIxNYBG-train"
csv_path = "/content/BTTAIxNYBG-train.csv"
validation_path = "/content/BTTAIxNYBG-train/BTTAIxNYBG-validation"
# Read CSV file
train_data = pd.read_csv(csv_path)

# Create subfolders for each label
labels = train_data['classID'].unique()
for label in labels:
    label_folder = os.path.join(folder_path, str(label))
    os.makedirs(label_folder, exist_ok=True)

# Move images to respective label folders
for index, row in train_data.iterrows():
    image_path = os.path.join(folder_path, row['imageFile'])
    label_folder = os.path.join(folder_path, str(row['classID']))
    shutil.move(image_path, label_folder)

# Move images to respective label folders (Validation)
#for index, row in train_data.iterrows():
    #image_path_validation = os.path.join(validation_path, row['imageFile'])
    #label_folder_validation = os.path.join(validation_path, str(row['classID']))
    #shutil.move(image_path_validation, label_folder_validation)

!pip install cjm_pil_utils

from pathlib import Path

from cjm_pil_utils.core import resize_img, get_img_files, stack_imgs
label_name = list(train_data['classID'].unique())
train_folders = [folder for folder in Path(folder_path).glob('*/') if folder.is_dir()]
train_img_paths = [get_img_files(folder) for folder in train_folders]
train_img_paths = [path for class_paths in train_img_paths for path in class_paths]

validation_folders = [folder for folder in Path(validation_path).glob('*/') if folder.is_dir()]
validation_img_paths = [get_img_files(folder) for folder in validation_folders]
validation_img_paths = [path for class_paths in validation_img_paths for path in class_paths]

len(train_img_paths)

len(train_img_paths) # now the training_img_paths are done with processing

"""**Display Random Image**"""

# Select a random image path from the list of image paths
from PIL import Image
import random
img_path = random.choice(train_img_paths)

# Print the name of the class of the image, which is the name of the parent folder
print(f"Class: {img_path.parent.name}")

# Open the image using the path
sample_img = Image.open(img_path)

# Display the image
sample_img

"""**Image Transformation**"""

norm_stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
norm_stats

# ensure the image transforming into appropriate size for model
train_sz = (288,288)

import torch.nn as nn
class ResizePad(nn.Module):
    def __init__(self, max_sz=256, padding_mode='edge'):
        """
        A PyTorch module that resizes an image tensor and adds padding to make it a square tensor.

        Args:
        max_sz (int, optional): The size of the square tensor.
        padding_mode (str, optional): The padding mode used when adding padding to the tensor.
        """
        super().__init__()
        self.max_sz = max_sz
        self.padding_mode = padding_mode

    def forward(self, x):
        # Get the width and height of the image tensor
        w, h = TF.get_image_size(x)

        # Resize the image tensor so that its minimum dimension is equal to `max_sz`
        size = int(min(w, h) / (max(w, h) / self.max_sz))
        x = TF.resize(x, size=size)

        # Add padding to make the image tensor a square
        w, h = TF.get_image_size(x)
        offset = (self.max_sz - min(w, h)) // 2
        padding = [0, offset] if h < w else [offset, 0]
        x = TF.pad(x, padding=padding, padding_mode=self.padding_mode)
        x = TF.resize(x, size=[self.max_sz] * 2)

        return x

from torch.utils.data import Dataset, DataLoader
class ImageDataset(Dataset):
    def __init__(self, img_paths, classes, tfms):
        # Store the arguments as instance variables
        self.img_paths = img_paths
        self.classes = classes
        self.tfms = tfms

        # Create a mapping from class names to class indices
        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}

    def __len__(self):
        # Return the number of images in the dataset
        return len(self.img_paths)

    def __getitem__(self, index):
        # Get the path of the image at the given index
        img_path = self.img_paths[index]

        # Get the label of the image
        label = self.class_to_idx[img_path.parent.name]

        # Open the image
        image = Image.open(img_path).convert('RGB')

        return self.tfms(image), label

train_tfms = [ResizePad(max_sz=max(train_sz))] # image transform

!pip install torch torchvision torchaudio torcheval

# create the training dataset using the composed transformations
from torchvision import datasets, transforms, models
import multiprocessing
train_dataset = ImageDataset(img_paths=train_img_paths,
                             classes=label_name,
                             tfms=transforms.Compose(train_tfms))

bs = 64 # batch size
train_dataloader = DataLoader(train_dataset,
                              batch_size=bs,
                              shuffle=True,
                              num_workers=multiprocessing.cpu_count())

"""**Validation Dataloader**"""

validation_tfms = [ResizePad(max_sz=max(train_sz))] # image transform
# create the training dataset using the composed transformations
from torchvision import datasets, transforms, models
import multiprocessing
validation_dataset = ImageDataset(img_paths=validation_img_paths,
                             classes=label_name,
                             tfms=transforms.Compose(validation_tfms))
bs = 64 # batch size
#validation_dataloader = DataLoader(validation_dataset,
                              #batch_size=bs,
                              #shuffle=True,
                              #num_workers=multiprocessing.cpu_count())

"""**ResNet-18**"""

torch.cuda.empty_cache()

num_classes = 19
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
model=models.resnet18(num_classes=num_classes).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9)

def train_one_epoch(epoch_index, tb_writer):
  #device = device or torch.device("cpu")
  running_loss = 0.
  last_loss = 0.
  i=0

    # Here, we use enumerate(training_loader) instead of
    # iter(training_loader) so that we can track the batch
    # index and do some intra-epoch reporting


  model.train()
  for i, data in enumerate(train_dataloader):
  #for images, labels in train_dataloader:
    images, labels = data
    images, labels = images.to(device), labels.to(device)
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

        # Gather data and report
    running_loss += loss.item()
    if i % 100 == 99:
            last_loss = running_loss / 1000 # loss per batch
            print('  batch {} loss: {}'.format(i + 1, last_loss))
            tb_x = epoch_index * len(train_dataloader) + i + 1
            tb_writer.add_scalar('Loss/train', last_loss, tb_x)
            running_loss = 0.

  return last_loss

from torch.utils.tensorboard import SummaryWriter
from datetime import datetime
# Initializing in a separate cell so we can easily add more epochs to the same run
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))
epoch_number = 0

EPOCHS = 5

best_vloss = 1_000_000.
# train_loss_history
train_loss_hist = []
# validation_loss_history
val_loss_hist = []

for epoch in range(EPOCHS):
    all_predictions = []
    all_labels = []
    loss_history_epoch = []
    print('EPOCH {}:'.format(epoch_number + 1))

    # Make sure gradient tracking is on, and do a pass over the data
    model.train(True)
    avg_loss = train_one_epoch(epoch_number, writer)


    running_vloss = 0.0
    # Set the model to evaluation mode, disabling dropout and using population
    # statistics for batch normalization.
    model.eval()

    # Disable gradient computation and reduce memory consumption.
    with torch.no_grad():
        for i, vdata in enumerate(valid_dataloader):
            vinputs, vlabels = vdata
            vinputs = vinputs.to(device)
            vlabels = vlabels.to(device)
            voutputs = model(vinputs)
            vloss = criterion(voutputs, vlabels)
            running_vloss += vloss
            all_predictions.extend(torch.argmax(voutputs, dim=1).cpu().numpy())
            all_labels.extend(vlabels.cpu().numpy())


    avg_vloss = running_vloss / (i + 1)
    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))
    accuracy = (torch.tensor(all_predictions) == torch.tensor(all_labels)).float().mean().item()
    print('test accuracy: ',accuracy)

    # Log the running loss averaged per batch
    # for both training and validation
    writer.add_scalars('Training vs. Validation Loss',
                    { 'Training' : avg_loss, 'Validation' : avg_vloss },
                    epoch_number + 1)
    train_loss_hist.append(avg_loss)
    val_loss_hist.append(avg_vloss)
    writer.flush()

    # Track best performance, and save the model's state
    if avg_vloss < best_vloss:
        best_vloss = avg_vloss
        model_path = 'model_{}_{}'.format(timestamp, epoch_number)
        torch.save(model.state_dict(), model_path)

    epoch_number += 1

"""**Training Loss Visualization**"""

print(type(val_loss_hist[0]))
print(type(train_loss_hist[0]))

val_loss_hist_cpu = [tensor.cpu() for tensor in val_loss_hist]

import matplotlib.pyplot as plt
plt.title('Original trained model: ResNet18')
plt.plot(train_loss_hist, 'r', label = 'Training Loss')
plt.plot(val_loss_hist_cpu, 'b', label = 'Validation Loss')
plt.legend()

torch.save(model.state_dict(), '/content/ResNet18.pth')

model.eval()

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")